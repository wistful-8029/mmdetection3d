{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmdet3d.apis import init_model, inference_detector, show_result_meshlab, inference_multi_modality_detector\n",
    "\n",
    "config_file = '/home/wistful/work/mmdetection3d/configs/mvxnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class.py'\n",
    "checkpoint_file = '/home/wistful/ResultDir/my_pth/mxvnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wistful/work/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:85: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  'dir_offset and dir_limit_offset will be depressed and be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/wistful/ResultDir/my_pth/mxvnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth\n"
     ]
    }
   ],
   "source": [
    "model = init_model(config_file, checkpoint_file, 'cuda:1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms  # 取数据\n",
    "from mmdet3d.datasets import build_dataset\n",
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(config_file)\n",
    "# 读取数据集\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img_metas', 'points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'img_metas': DataContainer({'filename': '/home/wistful/work/mmdetection3d/data/kitti/training/image_2/000000.png', 'ori_shape': (370, 1224, 3), 'img_shape': (264, 873, 3), 'lidar2img': array([[ 6.02943726e+02, -7.07913330e+02, -1.22748432e+01,\n         -1.70942719e+02],\n        [ 1.76777252e+02,  8.80879879e+00, -7.07936157e+02,\n         -1.02568634e+02],\n        [ 9.99984801e-01, -1.52826728e-03, -5.29071223e-03,\n         -3.27567995e-01],\n        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          1.00000000e+00]], dtype=float32), 'pad_shape': (288, 896, 3), 'scale_factor': array([0.7132353, 0.7135135, 0.7132353, 0.7135135], dtype=float32), 'flip': True, 'pcd_horizontal_flip': True, 'pcd_vertical_flip': False, 'box_mode_3d': <Box3DMode.LIDAR: 0>, 'box_type_3d': <class 'mmdet3d.core.bbox.structures.lidar_box3d.LiDARInstance3DBoxes'>, 'img_norm_cfg': {'mean': array([103.53 , 116.28 , 123.675], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}, 'pcd_trans': array([-0.39246847,  0.1711986 , -0.10559292]), 'sample_idx': 0, 'pcd_scale_factor': 1.0085284920743143, 'pcd_rotation': tensor([[ 0.9410,  0.3385,  0.0000],\n         [-0.3385,  0.9410,  0.0000],\n         [ 0.0000,  0.0000,  1.0000]]), 'pcd_rotation_angle': 0.3453157173116048, 'pts_filename': '/home/wistful/work/mmdetection3d/data/kitti/training/velodyne_reduced/000000.bin', 'transformation_3d_flow': ['R', 'S', 'T', 'HF']}),\n 'points': DataContainer(tensor([[  6.0598,   1.1250,  -0.9144,   0.0000],\n         [ 18.0496,  -3.7893,  -1.0637,   0.4000],\n         [ 12.6238,  -1.4366,   0.2353,   0.2600],\n         ...,\n         [  8.5840,  -1.3446,  -0.9639,   0.3300],\n         [ 12.1707, -12.2274,   0.1576,   0.1400],\n         [  7.5593,  -4.3243,  -1.7172,   0.1700]])),\n 'img': DataContainer(tensor([[[ -87.5300,  -81.5300,  -80.5300,  ...,    0.0000,    0.0000,\n              0.0000],\n          [ -88.5300,  -79.5300,  -78.5300,  ...,    0.0000,    0.0000,\n              0.0000],\n          [ -91.5300,  -81.5300,  -79.5300,  ...,    0.0000,    0.0000,\n              0.0000],\n          ...,\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000],\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000],\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000]],\n \n         [[ -98.2800,  -89.2800,  -85.2800,  ...,    0.0000,    0.0000,\n              0.0000],\n          [ -98.2800,  -89.2800,  -85.2800,  ...,    0.0000,    0.0000,\n              0.0000],\n          [-100.2800,  -92.2800,  -87.2800,  ...,    0.0000,    0.0000,\n              0.0000],\n          ...,\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000],\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000],\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000]],\n \n         [[ -87.6750,  -87.6750,  -84.6750,  ...,    0.0000,    0.0000,\n              0.0000],\n          [ -91.6750,  -89.6750,  -82.6750,  ...,    0.0000,    0.0000,\n              0.0000],\n          [ -95.6750,  -92.6750,  -87.6750,  ...,    0.0000,    0.0000,\n              0.0000],\n          ...,\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000],\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000],\n          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n              0.0000]]])),\n 'gt_bboxes_3d': DataContainer(LiDARInstance3DBoxes(\n     tensor([[ 8.5271, -1.3907, -1.7189,  1.2102,  0.4841,  1.9061,  1.2355]]))),\n 'gt_labels_3d': DataContainer(tensor([0]))}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_data = datasets[0][0]\n",
    "print(one_data.keys())\n",
    "one_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 72, 224])\n",
      "torch.Size([1, 256, 36, 112])\n",
      "torch.Size([1, 256, 18, 56])\n",
      "torch.Size([1, 256, 9, 28])\n",
      "torch.Size([1, 256, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "extract_img_feat = model.extract_img_feat\n",
    "# 获取图像特征，此处获取的是图像经过骨干和neck之后的数据，为5个通道数为256的特征\n",
    "img_feats = extract_img_feat((one_data.get('img').data).unsqueeze(dim=0).cuda(), [one_data.get('img_metas').data])\n",
    "for i in img_feats:\n",
    "    print(i.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wistful/work/mmdetection3d/mmdet3d/models/fusion_layers/coord_transform.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if 'pcd_rotation' in img_meta else torch.eye(\n"
     ]
    }
   ],
   "source": [
    "extract_pts_feat = model.extract_pts_feat\n",
    "# 获取图像特征，此处同上面各个字段的类型需要去代码里看定义\n",
    "img_feat_list = list(img_feats)\n",
    "pts_feats = extract_pts_feat([one_data.get('points').data.cuda()], img_feat_list, [one_data.get('img_metas').data])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_score: torch.Size([1, 18, 200, 176])\n",
      "bbox_pred: torch.Size([1, 42, 200, 176])\n",
      "dir_cls_preds: torch.Size([1, 12, 200, 176])\n"
     ]
    }
   ],
   "source": [
    "# 此处的head为Anchor3DHead，返回值有三个： cls_score, bbox_pred, dir_cls_preds\n",
    "# 其中，clas_score 通道数为  num_classes * num_anchors, num_classes在配置文件中\n",
    "# bbox_pred 通道数为 num_anchors * box_code_size\n",
    "# dir_cls_preds 通道数为 num_anchors * 2\n",
    "# 得到head的输出后，还需要运行一下解码模块，才能得到最终的bbox和分类情况\n",
    "pts_bbox_head = model.pts_bbox_head\n",
    "pts_out = pts_bbox_head(pts_feats)  # tuple[list[torch.Tensor]]\n",
    "cls_score, bbox_pred, dir_cls_preds = pts_out\n",
    "print(\"cls_score:\",cls_score[0].shape)\n",
    "print(\"bbox_pred:\",bbox_pred[0].shape)\n",
    "print(\"dir_cls_preds:\",dir_cls_preds[0].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mmdet3d.core.bbox.structures.lidar_box3d.LiDARInstance3DBoxes'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "LiDARInstance3DBoxes(\n    tensor([[  8.5166,  -1.4354,  -1.6564,   1.2415,   0.5879,   1.9521,   1.2375],\n        [ 14.0160, -21.8561,  -1.8352,   1.7213,   0.5980,   1.6781,   4.0820],\n        [  8.7474,  -1.3463,  -1.5435,   4.0260,   1.8987,   1.7594,  -0.3487]],\n       device='cuda:1'))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将head得到的输出编码为bboxer\n",
    "bboxes = model.pts_bbox_head.get_bboxes(cls_score,bbox_pred,dir_cls_preds,[one_data.get('img_metas').data])\n",
    "print(type(bboxes[0][0])) # 是在LiDAR坐标系下\n",
    "bboxes_data = bboxes[0][0] # 得到了4个预测框\n",
    "bboxes_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# from mmdet3d.core import Box3DMode\n",
    "#  # 将LiDAR BBOX转换到深度坐标系\n",
    "# gt_bboxes_cam = bboxes_data.convert_to(dst=Box3DMode.DEPTH, rt_mat=None)\n",
    "# # gt_bboxes_cam = gt_bboxes_cam.tensor\n",
    "# gt_bboxes_cam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiDARInstance3DBoxes(\n",
      "    tensor([[ 8.5271, -1.3907, -1.7189,  1.2102,  0.4841,  1.9061,  1.2355]]))\n",
      "LiDARInstance3DBoxes(\n",
      "    tensor([[  8.5166,  -1.4354,  -1.6564,   1.2415,   0.5879,   1.9521,   1.2375],\n",
      "        [ 14.0160, -21.8561,  -1.8352,   1.7213,   0.5980,   1.6781,   4.0820],\n",
      "        [  8.7474,  -1.3463,  -1.5435,   4.0260,   1.8987,   1.7594,  -0.3487]],\n",
      "       device='cuda:1'))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "img_metas = one_data.get('img_metas').data\n",
    "img_file_path = img_metas['filename']\n",
    "\n",
    "img = cv2.imread(img_file_path)\n",
    "\n",
    "front_mat = one_data.get('img_metas').data.get('lidar2img')\n",
    "# front_mat\n",
    "from mmdet3d.core import show_multi_modality_result\n",
    "# image2CV = img.permute(1,2,0) # 交换维度，转换为openCV支持的格式：[H, W, C]\n",
    "\n",
    "\n",
    "gt_boxes = one_data.get('gt_bboxes_3d').data\n",
    "print(gt_boxes)\n",
    "print(bboxes_data)\n",
    "# gt_bboxes_cam\n",
    "bboxes_data = bboxes_data.to('cpu')\n",
    "show_multi_modality_result(img=img,\n",
    "                           box_mode='lidar',\n",
    "                           gt_bboxes=gt_boxes,\n",
    "                           img_metas=img_metas,\n",
    "                           pred_bboxes=bboxes_data,\n",
    "                           proj_mat=front_mat,\n",
    "                           out_dir=\"/home/wistful/work/mmdetection3d/visual_img/\",\n",
    "                           filename=\"test\",\n",
    "                           show=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  8.5166,  -1.4354,  -1.6564,   1.2415,   0.5879,   1.9521,   1.2375],\n        [ 14.0160, -21.8561,  -1.8352,   1.7213,   0.5980,   1.6781,   4.0820],\n        [  8.7474,  -1.3463,  -1.5435,   4.0260,   1.8987,   1.7594,  -0.3487],\n        [  8.5271,  -1.3907,  -1.7189,   1.2102,   0.4841,   1.9061,   1.2355]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "all_boxes = torch.cat((bboxes_data.tensor,gt_boxes.tensor))\n",
    "all_boxes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "point_file = \"/home/wistful/work/mmdetection3d/demo/data/kitti/kitti_000008.bin\"\n",
    "img_file = '/home/wistful/work/mmdetection3d/demo/data/kitti/kitti_000008.png'\n",
    "ann_file = '/home/wistful/work/mmdetection3d/demo/data/kitti/kitti_000008_infos.pkl'\n",
    "out_dir = '/home/wistful/work/mmdetection3d/visual_img'\n",
    "result, data = inference_multi_modality_detector(model=model, pcd=point_file,image=img_file, ann_file=ann_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "('/home/wistful/work/mmdetection3d/visual_img', 'kitti_000008')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmdet3d.apis import show_result_meshlab\n",
    "\"\"\"\n",
    "assert task in ['det', 'multi_modality-det', 'seg', 'mono-det'], \\\n",
    "        f'unsupported visualization task {task}'\n",
    "\"\"\"\n",
    "show_result_meshlab(data,result,out_dir,show=False,score_thr=0.3,task='multi_modality-det')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mmdetection3d",
   "language": "python",
   "display_name": "mmdetection3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
